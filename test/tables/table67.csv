CWE-ID,Name,Weakness Abstraction,Status,Description,Extended Description
200,Exposure of Sensitive Information to an Unauthorized Actor,Class,Draft,The product exposes sensitive information to an actor that is not explicitly authorized to have access to that information.,There are many different kinds of mistakes that introduce information exposures. The severity of the error can range widely, depending on the context in which the product operates, the type of sensitive information that is revealed, and the benefits it may provide to an attacker. Some kinds of sensitive information include: private, personal information, such as personal messages, financial data, health records, geographic location, or contact details system status and environment, such as the operating system and installed packages business secrets and intellectual property network status and configuration the product's own code or internal state metadata, e.g. logging of connections or message headers indirect information, such as a discrepancy between two internal operations that can be observed by an outsider Information might be sensitive to different parties, each of which may have their own expectations for whether the information should be protected. These parties include: the product's own users people or organizations whose information is created or used by the product, even if they are not direct product users the product's administrators, including the admins of the system(s) and/or networks on which the product operates the developer Information exposures can occur in different ways: the code explicitly inserts sensitive information into resources or messages that are intentionally made accessible to unauthorized actors, but should not contain the information - i.e., the information should have been scrubbed or sanitized a different weakness or mistake indirectly inserts the sensitive information into resources, such as a web script error revealing the full system path of the program. the code manages resources that intentionally contain sensitive information, but the resources are unintentionally made accessible to unauthorized actors. In this case, the information exposure is resultant - i.e., a different weakness enabled the access to the information in the first place. It is common practice to describe any loss of confidentiality as an information exposure, but this can lead to overuse of CWE-200 in CWE mapping. From the CWE perspective, loss of confidentiality is a technical impact that can arise from dozens of different weaknesses, such as insecure file permissions or out-of-bounds read. CWE-200 and its lower-level descendants are intended to cover the mistakes that occur in behaviors that explicitly manage, store, transfer, or cleanse sensitive information.
201,Insertion of Sensitive Information Into Sent Data,Base,Draft,The code transmits data to another actor, but a portion of the data includes sensitive information that should not be accessible to that actor.,Sensitive information could include data that is sensitive in and of itself (such as credentials or private messages), or otherwise useful in the further exploitation of the system (such as internal file system structure).
202,Exposure of Sensitive Information Through Data Queries,Variant,Draft,When trying to keep information confidential, an attacker can often infer some of the information by using statistics.,In situations where data should not be tied to individual users, but a large number of users should be able to make queries that scrub the identity of users, it may be possible to get information about a user -- e.g., by specifying search terms that are known to be unique to that user.
203,Observable Discrepancy,Base,Incomplete,The product behaves differently or sends different responses under different circumstances in a way that is observable to an unauthorized actor, which exposes security-relevant information about the state of the product, such as whether a particular operation was successful or not.,Discrepancies can take many forms, and variations may be detectable in timing, control flow, communications such as replies or requests, or general behavior. These discrepancies can reveal information about the product's operation or internal state to an unauthorized actor. In some cases, discrepancies can be used by attackers to form a side channel.
204,Observable Response Discrepancy,Base,Incomplete,The product provides different responses to incoming requests in a way that reveals internal state information to an unauthorized actor outside of the intended control sphere.,This issue frequently occurs during authentication, where a difference in failed-login messages could allow an attacker to determine if the username is valid or not. These exposures can be inadvertent (bug) or intentional (design).
205,Observable Behavioral Discrepancy,Base,Incomplete,The product's behaviors indicate important differences that may be observed by unauthorized actors in a way that reveals (1) its internal state or decision process, or (2) differences from other products with equivalent functionality.,Ideally, a product should provide as little information about its internal operations as possible. Otherwise, attackers could use knowledge of these internal operations to simplify or optimize their attack. In some cases, behavioral discrepancies can be used by attackers to form a side channel.
206,Observable Internal Behavioral Discrepancy,Variant,Incomplete,The product performs multiple behaviors that are combined to produce a single result, but the individual behaviors are observable separately in a way that allows attackers to reveal internal state or internal decision points.,Ideally, a product should provide as little information as possible to an attacker. Any hints that the attacker may be making progress can then be used to simplify or optimize the attack. For example, in a login procedure that requires a username and password, ultimately there is only one decision: success or failure. However, internally, two separate actions are performed: determining if the username exists, and checking if the password is correct. If the product behaves differently based on whether the username exists or not, then the attacker only needs to concentrate on the password.
207,Observable Behavioral Discrepancy With Equivalent Products,Variant,Draft,The product operates in an environment in which its existence or specific identity should not be known, but it behaves differently than other products with equivalent functionality, in a way that is observable to an attacker.,For many kinds of products, multiple products may be available that perform the same functionality, such as a web server, network interface, or intrusion detection system. Attackers often perform fingerprinting, which uses discrepancies in order to identify which specific product is in use. Once the specific product has been identified, the attacks can be made more customized and efficient. Often, an organization might intentionally allow the specific product to be identifiable. However, in some environments, the ability to identify a distinct product is unacceptable, and it is expected that every product would behave in exactly the same way. In these more restricted environments, a behavioral difference might pose an unacceptable risk if it makes it easier to identify the product's vendor, model, configuration, version, etc.
208,Observable Timing Discrepancy,Base,Incomplete,Two separate operations in a product require different amounts of time to complete, in a way that is observable to an actor and reveals security-relevant information about the state of the product, such as whether a particular operation was successful or not.,In security-relevant contexts, even small variations in timing can be exploited by attackers to indirectly infer certain details about the product's internal operations. For example, in some cryptographic algorithms, attackers can use timing differences to infer certain properties about a private key, making the key easier to guess. Timing discrepancies effectively form a timing side channel.
209,Generation of Error Message Containing Sensitive Information,Base,Draft,The product generates an error message that includes sensitive information about its environment, users, or associated data.,The sensitive information may be valuable information on its own (such as a password), or it may be useful for launching other, more serious attacks. The error message may be created in different ways: self-generated: the source code explicitly constructs the error message and delivers it externally-generated: the external environment, such as a language interpreter, handles the error and constructs its own message, whose contents are not under direct control by the programmer An attacker may use the contents of error messages to help launch another, more focused attack. For example, an attempt to exploit a path traversal weakness (CWE-22) might yield the full pathname of the installed application. In turn, this could be used to select the proper number of .. sequences to navigate to the targeted file. An attack using SQL injection (CWE-89) might not initially succeed, but an error message could reveal the malformed query, which would expose query logic and possibly even passwords or other sensitive information used within the query.
210,Self-generated Error Message Containing Sensitive Information,Base,Draft,The product identifies an error condition and creates its own diagnostic or error messages that contain sensitive information.,
211,Externally-Generated Error Message Containing Sensitive Information,Base,Incomplete,The product performs an operation that triggers an external diagnostic or error message that is not directly generated or controlled by the product, such as an error generated by the programming language interpreter that a software application uses. The error can contain sensitive system information.,
212,Improper Removal of Sensitive Information Before Storage or Transfer,Base,Incomplete,The product stores, transfers, or shares a resource that contains sensitive information, but it does not properly remove that information before the product makes the resource available to unauthorized actors.,Resources that may contain sensitive data include documents, packets, messages, databases, etc. While this data may be useful to an individual user or small set of users who share the resource, it may need to be removed before the resource can be shared outside of the trusted group. The process of removal is sometimes called cleansing or scrubbing. For example, a product for editing documents might not remove sensitive data such as reviewer comments or the local pathname where the document is stored. Or, a proxy might not remove an internal IP address from headers before making an outgoing request to an Internet site.
213,Exposure of Sensitive Information Due to Incompatible Policies,Base,Draft,The product's intended functionality exposes information to certain actors in accordance with the developer's security policy, but this information is regarded as sensitive according to the intended security policies of other stakeholders such as the product's administrator, users, or others whose information is being processed.,When handling information, the developer must consider whether the information is regarded as sensitive by different stakeholders, such as users or administrators. Each stakeholder effectively has its own intended security policy that the product is expected to uphold. When a developer does not treat that information as sensitive, this can introduce a vulnerability that violates the expectations of the product's users.
214,Invocation of Process Using Visible Sensitive Information,Base,Incomplete,A process is invoked with sensitive command-line arguments, environment variables, or other elements that can be seen by other processes on the operating system.,Many operating systems allow a user to list information about processes that are owned by other users. Other users could see information such as command line arguments or environment variable settings. When this data contains sensitive information such as credentials, it might allow other users to launch an attack against the product or related resources.
215,Insertion of Sensitive Information Into Debugging Code,Base,Draft,The product inserts sensitive information into debugging code, which could expose this information if the debugging code is not disabled in production.,When debugging, it may be necessary to report detailed information to the programmer. However, if the debugging code is not disabled when the product is operating in a production environment, then this sensitive information may be exposed to attackers.
219,Storage of File with Sensitive Data Under Web Root,Variant,Draft,The product stores sensitive data under the web document root with insufficient access control, which might make it accessible to untrusted parties.,Besides public-facing web pages and code, products may store sensitive data, code that is not directly invoked, or other files under the web document root of the web server. If the server is not configured or otherwise used to prevent direct access to those files, then attackers may obtain this sensitive data.
220,Storage of File With Sensitive Data Under FTP Root,Variant,Draft,The product stores sensitive data under the FTP server root with insufficient access control, which might make it accessible to untrusted parties.,
221,Information Loss or Omission,Class,Incomplete,The product does not record, or improperly records, security-relevant information that leads to an incorrect decision or hampers later analysis.,This can be resultant, e.g. a buffer overflow might trigger a crash before the product can log the event.
222,Truncation of Security-relevant Information,Base,Draft,The product truncates the display, recording, or processing of security-relevant information in a way that can obscure the source or nature of an attack.,
223,Omission of Security-relevant Information,Base,Draft,The product does not record or display information that would be important for identifying the source or nature of an attack, or determining if an action is safe.,
224,Obscured Security-relevant Information by Alternate Name,Base,Incomplete,The product records security-relevant information according to an alternate name of the affected entity, instead of the canonical name.,
226,Sensitive Information in Resource Not Removed Before Reuse,Base,Draft,The product releases a resource such as memory or a file so that it can be made available for reuse, but it does not clear or zeroize the information contained in the resource before the product performs a critical state transition or makes the resource available for reuse by other entities.,When resources are released, they can be made available for reuse. For example, after memory is de-allocated, an operating system may make the memory available to another process, or disk space may be reallocated when a file is deleted. As removing information requires time and additional resources, operating systems do not usually clear the previously written information. Even when the resource is reused by the same process, this weakness can arise when new data is not as large as the old data, which leaves portions of the old data still available. Equivalent errors can occur in other situations where the length of data is variable but the associated data structure is not. If memory is not cleared after use, the information may be read by less trustworthy parties when the memory is reallocated. This weakness can apply in hardware, such as when a device or system switches between power, sleep, or debug states during normal operation, or when execution changes to different users or privilege levels.
228,Improper Handling of Syntactically Invalid Structure,Class,Incomplete,The product does not handle or incorrectly handles input that is not syntactically well-formed with respect to the associated specification.,
229,Improper Handling of Values,Base,Incomplete,The product does not properly handle when the expected number of values for parameters, fields, or arguments is not provided in input, or if those values are undefined.,
230,Improper Handling of Missing Values,Variant,Draft,The product does not handle or incorrectly handles when a parameter, field, or argument name is specified, but the associated value is missing, i.e. it is empty, blank, or null.,
231,Improper Handling of Extra Values,Variant,Draft,The product does not handle or incorrectly handles when more values are provided than expected.,
232,Improper Handling of Undefined Values,Variant,Draft,The product does not handle or incorrectly handles when a value is not defined or supported for the associated parameter, field, or argument name.,
233,Improper Handling of Parameters,Base,Incomplete,The product does not properly handle when the expected number of parameters, fields, or arguments is not provided in input, or if those parameters are undefined.,
234,Failure to Handle Missing Parameter,Variant,Incomplete,If too few arguments are sent to a function, the function will still pop the expected number of arguments from the stack. Potentially, a variable number of arguments could be exhausted in a function as well.,
235,Improper Handling of Extra Parameters,Variant,Draft,The product does not handle or incorrectly handles when the number of parameters, fields, or arguments with the same name exceeds the expected amount.,
236,Improper Handling of Undefined Parameters,Variant,Draft,The product does not handle or incorrectly handles when a particular parameter, field, or argument name is not defined or supported by the product.,
237,Improper Handling of Structural Elements,Base,Incomplete,The product does not handle or incorrectly handles inputs that are related to complex structures.,
238,Improper Handling of Incomplete Structural Elements,Variant,Draft,The product does not handle or incorrectly handles when a particular structural element is not completely specified.,
239,Failure to Handle Incomplete Element,Variant,Draft,The product does not properly handle when a particular element is not completely specified.,
240,Improper Handling of Inconsistent Structural Elements,Base,Draft,The product does not handle or incorrectly handles when two or more structural elements should be consistent, but are not.,
241,Improper Handling of Unexpected Data Type,Base,Draft,The product does not handle or incorrectly handles when a particular element is not the expected type, e.g. it expects a digit (0-9) but is provided with a letter (A-Z).,
242,Use of Inherently Dangerous Function,Base,Draft,The product calls a function that can never be guaranteed to work safely.,Certain functions behave in dangerous ways regardless of how they are used. Functions in this category were often implemented without taking security concerns into account. The gets() function is unsafe because it does not perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized input to gets() and overflow the destination buffer. Similarly, the >> operator is unsafe to use when reading into a statically-allocated character array because it does not perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized input to the >> operator and overflow the destination buffer.
243,Creation of chroot Jail Without Changing Working Directory,Variant,Draft,The product uses the chroot() system call to create a jail, but does not change the working directory afterward. This does not prevent access to files outside of the jail.,Improper use of chroot() may allow attackers to escape from the chroot jail. The chroot() function call does not change the process's current working directory, so relative paths may still refer to file system resources outside of the chroot jail after chroot() has been called.
244,Improper Clearing of Heap Memory Before Release ('Heap Inspection'),Variant,Draft,Using realloc() to resize buffers that store sensitive information can leave the sensitive information exposed to attack, because it is not removed from memory.,When sensitive data such as a password or an encryption key is not removed from memory, it could be exposed to an attacker using a heap inspection attack that reads the sensitive data using memory dumps or other methods. The realloc() function is commonly used to increase the size of a block of allocated memory. This operation often requires copying the contents of the old memory block into a new and larger block. This operation leaves the contents of the original block intact but inaccessible to the program, preventing the program from being able to scrub sensitive data from memory. If an attacker can later examine the contents of a memory dump, the sensitive data could be exposed.
245,J2EE Bad Practices: Direct Management of Connections,Variant,Draft,The J2EE application directly manages connections, instead of using the container's connection management facilities.,The J2EE standard forbids the direct management of connections. It requires that applications use the container's resource management facilities to obtain connections to resources. Every major web application container provides pooled database connection management as part of its resource management framework. Duplicating this functionality in an application is difficult and error prone, which is part of the reason it is forbidden under the J2EE standard.
246,J2EE Bad Practices: Direct Use of Sockets,Variant,Draft,The J2EE application directly uses sockets instead of using framework method calls.,The J2EE standard permits the use of sockets only for the purpose of communication with legacy systems when no higher-level protocol is available. Authoring your own communication protocol requires wrestling with difficult security issues. Without significant scrutiny by a security expert, chances are good that a custom communication protocol will suffer from security problems. Many of the same issues apply to a custom implementation of a standard protocol. While there are usually more resources available that address security concerns related to implementing a standard protocol, these resources are also available to attackers.
248,Uncaught Exception,Base,Draft,An exception is thrown from a function, but it is not caught.,When an exception is not caught, it may cause the program to crash or expose sensitive information.
250,Execution with Unnecessary Privileges,Base,Draft,The product performs an operation at a privilege level that is higher than the minimum level required, which creates new weaknesses or amplifies the consequences of other weaknesses.,New weaknesses can be exposed because running with extra privileges, such as root or Administrator, can disable the normal security checks being performed by the operating system or surrounding environment. Other pre-existing weaknesses can turn into security vulnerabilities if they occur while operating at raised privileges. Privilege management functions can behave in some less-than-obvious ways, and they have different quirks on different platforms. These inconsistencies are particularly pronounced if you are transitioning from one non-root user to another. Signal handlers and spawned processes run at the privilege of the owning process, so if a process is running as root when a signal fires or a sub-process is executed, the signal handler or sub-process will operate with root privileges.
252,Unchecked Return Value,Base,Draft,The product does not check the return value from a method or function, which can prevent it from detecting unexpected states and conditions.,Two common programmer assumptions are this function call can never fail and it doesn't matter if this function call fails. If an attacker can force the function to fail or otherwise return a value that is not expected, then the subsequent program logic could lead to a vulnerability, because the product is not in a state that the programmer assumes. For example, if the program calls a function to drop privileges but does not check the return code to ensure that privileges were successfully dropped, then the program will continue to operate with the higher privileges.
253,Incorrect Check of Function Return Value,Base,Incomplete,The product incorrectly checks a return value from a function, which prevents it from detecting errors or exceptional conditions.,Important and common functions will return some value about the success of its actions. This will alert the program whether or not to handle any errors caused by that function.
256,Plaintext Storage of a Password,Base,Incomplete,Storing a password in plaintext may result in a system compromise.,Password management issues occur when a password is stored in plaintext in an application's properties, configuration file, or memory. Storing a plaintext password in a configuration file allows anyone who can read the file access to the password-protected resource. In some contexts, even storage of a plaintext password in memory is considered a security risk if the password is not cleared immediately after it is used.
257,Storing Passwords in a Recoverable Format,Base,Incomplete,The storage of passwords in a recoverable format makes them subject to password reuse attacks by malicious users. In fact, it should be noted that recoverable encrypted passwords provide no significant benefit over plaintext passwords since they are subject not only to reuse by malicious attackers but also by malicious insiders. If a system administrator can recover a password directly, or use a brute force search on the available information, the administrator can use the password on other accounts.,
258,Empty Password in Configuration File,Variant,Incomplete,Using an empty string as a password is insecure.,
259,Use of Hard-coded Password,Variant,Draft,The product contains a hard-coded password, which it uses for its own inbound authentication or for outbound communication to external components.,A hard-coded password typically leads to a significant authentication failure that can be difficult for the system administrator to detect. Once detected, it can be difficult to fix, so the administrator may be forced into disabling the product entirely. There are two main variations: Inbound: the product contains an authentication mechanism that checks for a hard-coded password. Outbound: the product connects to another system or component, and it contains hard-coded password for connecting to that component. In the Inbound variant, a default administration account is created, and a simple password is hard-coded into the product and associated with that account. This hard-coded password is the same for each installation of the product, and it usually cannot be changed or disabled by system administrators without manually modifying the program, or otherwise patching the product. If the password is ever discovered or published (a common occurrence on the Internet), then anybody with knowledge of this password can access the product. Finally, since all installations of the product will have the same password, even across different organizations, this enables massive attacks such as worms to take place. The Outbound variant applies to front-end systems that authenticate with a back-end service. The back-end service may require a fixed password which can be easily discovered. The programmer may simply hard-code those back-end credentials into the front-end product. Any user of that program may be able to extract the password. Client-side systems with hard-coded passwords pose even more of a threat, since the extraction of a password from a binary is usually very simple.
260,Password in Configuration File,Base,Incomplete,The product stores a password in a configuration file that might be accessible to actors who do not know the password.,This can result in compromise of the system for which the password is used. An attacker could gain access to this file and learn the stored password or worse yet, change the password to one of their choosing.
261,Weak Encoding for Password,Base,Incomplete,Obscuring a password with a trivial encoding does not protect the password.,Password management issues occur when a password is stored in plaintext in an application's properties or configuration file. A programmer can attempt to remedy the password management problem by obscuring the password with an encoding function, such as base 64 encoding, but this effort does not adequately protect the password.
262,Not Using Password Aging,Base,Draft,The product does not have a mechanism in place for managing password aging.,Password aging (or password rotation) is a policy that forces users to change their passwords after a defined time period passes, such as every 30 or 90 days. Without mechanisms such as aging, users might not change their passwords in a timely manner. Note that while password aging was once considered an important security feature, it has since fallen out of favor by many, because it is not as effective against modern threats compared to other mechanisms such as slow hashes. In addition, forcing frequent changes can unintentionally encourage users to select less-secure passwords. However, password aging is still in use due to factors such as compliance requirements, e.g., Payment Card Industry Data Security Standard (PCI DSS).
263,Password Aging with Long Expiration,Base,Draft,The product supports password aging, but the expiration period is too long.,Password aging (or password rotation) is a policy that forces users to change their passwords after a defined time period passes, such as every 30 or 90 days. A long expiration provides more time for attackers to conduct password cracking before users are forced to change to a new password. Note that while password aging was once considered an important security feature, it has since fallen out of favor by many, because it is not as effective against modern threats compared to other mechanisms such as slow hashes. In addition, forcing frequent changes can unintentionally encourage users to select less-secure passwords. However, password aging is still in use due to factors such as compliance requirements, e.g., Payment Card Industry Data Security Standard (PCI DSS).
266,Incorrect Privilege Assignment,Base,Draft,A product incorrectly assigns a privilege to a particular actor, creating an unintended sphere of control for that actor.,
267,Privilege Defined With Unsafe Actions,Base,Incomplete,A particular privilege, role, capability, or right can be used to perform unsafe actions that were not intended, even when it is assigned to the correct entity.,
268,Privilege Chaining,Base,Draft,Two distinct privileges, roles, capabilities, or rights can be combined in a way that allows an entity to perform unsafe actions that would not be allowed without that combination.,
269,Improper Privilege Management,Class,Draft,The product does not properly assign, modify, track, or check privileges for an actor, creating an unintended sphere of control for that actor.,
270,Privilege Context Switching Error,Base,Draft,The product does not properly manage privileges while it is switching between different contexts that have different privileges or spheres of control.,
271,Privilege Dropping / Lowering Errors,Class,Incomplete,The product does not drop privileges before passing control of a resource to an actor that does not have those privileges.,In some contexts, a system executing with elevated permissions will hand off a process/file/etc. to another process or user. If the privileges of an entity are not reduced, then elevated privileges are spread throughout a system and possibly to an attacker.
272,Least Privilege Violation,Base,Incomplete,The elevated privilege level required to perform operations such as chroot() should be dropped immediately after the operation is performed.,
273,Improper Check for Dropped Privileges,Base,Incomplete,The product attempts to drop privileges but does not check or incorrectly checks to see if the drop succeeded.,If the drop fails, the product will continue to run with the raised privileges, which might provide additional access to unprivileged users.
274,Improper Handling of Insufficient Privileges,Base,Draft,The product does not handle or incorrectly handles when it has insufficient privileges to perform an operation, leading to resultant weaknesses.,
276,Incorrect Default Permissions,Base,Draft,During installation, installed file permissions are set to allow anyone to modify those files.,
277,Insecure Inherited Permissions,Variant,Draft,A product defines a set of insecure permissions that are inherited by objects that are created by the program.,
278,Insecure Preserved Inherited Permissions,Variant,Incomplete,A product inherits a set of insecure permissions for an object, e.g. when copying from an archive file, without user awareness or involvement.,
279,Incorrect Execution-Assigned Permissions,Variant,Draft,While it is executing, the product sets the permissions of an object in a way that violates the intended permissions that have been specified by the user.,
280,Improper Handling of Insufficient Permissions or Privileges ,Base,Draft,The product does not handle or incorrectly handles when it has insufficient privileges to access resources or functionality as specified by their permissions. This may cause it to follow unexpected code paths that may leave the product in an invalid state.,
281,Improper Preservation of Permissions,Base,Draft,The product does not preserve permissions or incorrectly preserves permissions when copying, restoring, or sharing objects, which can cause them to have less restrictive permissions than intended.,
282,Improper Ownership Management,Class,Draft,The product assigns the wrong ownership, or does not properly verify the ownership, of an object or resource.,
283,Unverified Ownership,Base,Draft,The product does not properly verify that a critical resource is owned by the proper entity.,
284,Improper Access Control,Pillar,Incomplete,The product does not restrict or incorrectly restricts access to a resource from an unauthorized actor.,Access control involves the use of several protection mechanisms such as: Authentication (proving the identity of an actor) Authorization (ensuring that a given actor can access a resource), and Accountability (tracking of activities that were performed) When any mechanism is not applied or otherwise fails, attackers can compromise the security of the product by gaining privileges, reading sensitive information, executing commands, evading detection, etc. There are two distinct behaviors that can introduce access control weaknesses: Specification: incorrect privileges, permissions, ownership, etc. are explicitly specified for either the user or the resource (for example, setting a password file to be world-writable, or giving administrator capabilities to a guest user). This action could be performed by the program or the administrator. Enforcement: the mechanism contains errors that prevent it from properly enforcing the specified access control requirements (e.g., allowing the user to specify their own privileges, or allowing a syntactically-incorrect ACL to produce insecure settings). This problem occurs within the program itself, in that it does not actually enforce the intended security policy that the administrator specifies.
285,Improper Authorization,Class,Draft,The product does not perform or incorrectly performs an authorization check when an actor attempts to access a resource or perform an action.,Assuming a user with a given identity, authorization is the process of determining whether that user can access a given resource, based on the user's privileges and any permissions or other access-control specifications that apply to the resource. When access control checks are not applied consistently - or not at all - users are able to access data or perform actions that they should not be allowed to perform. This can lead to a wide range of problems, including information exposures, denial of service, and arbitrary code execution.
286,Incorrect User Management,Class,Incomplete,The product does not properly manage a user within its environment.,Users can be assigned to the wrong group (class) of permissions resulting in unintended access rights to sensitive objects.
287,Improper Authentication,Class,Draft,When an actor claims to have a given identity, the product does not prove or insufficiently proves that the claim is correct.,
288,Authentication Bypass Using an Alternate Path or Channel,Base,Incomplete,A product requires authentication, but the product has an alternate path or channel that does not require authentication.,
289,Authentication Bypass by Alternate Name,Base,Incomplete,The product performs authentication based on the name of a resource being accessed, or the name of the actor performing the access, but it does not properly check all possible names for that resource or actor.,
290,Authentication Bypass by Spoofing,Base,Incomplete,This attack-focused weakness is caused by incorrectly implemented authentication schemes that are subject to spoofing attacks.,
293,Using Referer Field for Authentication,Variant,Draft,The referer field in HTTP requests can be easily modified and, as such, is not a valid means of message integrity checking.,
294,Authentication Bypass by Capture-replay,Base,Incomplete,A capture-replay flaw exists when the design of the product makes it possible for a malicious user to sniff network traffic and bypass authentication by replaying it to the server in question to the same effect as the original message (or with minor changes).,Capture-replay attacks are common and can be difficult to defeat without cryptography. They are a subset of network injection attacks that rely on observing previously-sent valid commands, then changing them slightly if necessary and resending the same commands to the server.
296,Improper Following of a Certificate's Chain of Trust,Base,Draft,The product does not follow, or incorrectly follows, the chain of trust for a certificate back to a trusted root certificate, resulting in incorrect trust of any resource that is associated with that certificate.,If a system does not follow the chain of trust of a certificate to a root server, the certificate loses all usefulness as a metric of trust. Essentially, the trust gained from a certificate is derived from a chain of trust -- with a reputable trusted entity at the end of that list. The end user must trust that reputable source, and this reputable source must vouch for the resource in question through the medium of the certificate. In some cases, this trust traverses several entities who vouch for one another. The entity trusted by the end user is at one end of this trust chain, while the certificate-wielding resource is at the other end of the chain. If the user receives a certificate at the end of one of these trust chains and then proceeds to check only that the first link in the chain, no real trust has been derived, since the entire chain must be traversed back to a trusted source to verify the certificate. There are several ways in which the chain of trust might be broken, including but not limited to: Any certificate in the chain is self-signed, unless it the root. Not every intermediate certificate is checked, starting from the original certificate all the way up to the root certificate. An intermediate, CA-signed certificate does not have the expected Basic Constraints or other important extensions. The root certificate has been compromised or authorized to the wrong party.
297,Improper Validation of Certificate with Host Mismatch,Variant,Incomplete,The product communicates with a host that provides a certificate, but the product does not properly ensure that the certificate is actually associated with that host.,Even if a certificate is well-formed, signed, and follows the chain of trust, it may simply be a valid certificate for a different site than the site that the product is interacting with. If the certificate's host-specific data is not properly checked - such as the Common Name (CN) in the Subject or the Subject Alternative Name (SAN) extension of an X.509 certificate - it may be possible for a redirection or spoofing attack to allow a malicious host with a valid certificate to provide data, impersonating a trusted host. In order to ensure data integrity, the certificate must be valid and it must pertain to the site that is being accessed. Even if the product attempts to check the hostname, it is still possible to incorrectly check the hostname. For example, attackers could create a certificate with a name that begins with a trusted name followed by a NUL byte, which could cause some string-based comparisons to only examine the portion that contains the trusted name. This weakness can occur even when the product uses Certificate Pinning, if the product does not verify the hostname at the time a certificate is pinned.
298,Improper Validation of Certificate Expiration,Variant,Draft,A certificate expiration is not validated or is incorrectly validated, so trust may be assigned to certificates that have been abandoned due to age.,When the expiration of a certificate is not taken into account, no trust has necessarily been conveyed through it. Therefore, the validity of the certificate cannot be verified and all benefit of the certificate is lost.
299,Improper Check for Certificate Revocation,Base,Draft,The product does not check or incorrectly checks the revocation status of a certificate, which may cause it to use a certificate that has been compromised.,An improper check for certificate revocation is a far more serious flaw than related certificate failures. This is because the use of any revoked certificate is almost certainly malicious. The most common reason for certificate revocation is compromise of the system in question, with the result that no legitimate servers will be using a revoked certificate, unless they are sorely out of sync.
300,Channel Accessible by Non-Endpoint,Class,Draft,The product does not adequately verify the identity of actors at both ends of a communication channel, or does not adequately ensure the integrity of the channel, in a way that allows the channel to be accessed or influenced by an actor that is not an endpoint.,In order to establish secure communication between two parties, it is often important to adequately verify the identity of entities at each end of the communication channel. Inadequate or inconsistent verification may result in insufficient or incorrect identification of either communicating entity. This can have negative consequences such as misplaced trust in the entity at the other end of the channel. An attacker can leverage this by interposing between the communicating entities and masquerading as the original entity. In the absence of sufficient verification of identity, such an attacker can eavesdrop and potentially modify the communication between the original entities.
301,Reflection Attack in an Authentication Protocol,Base,Draft,Simple authentication protocols are subject to reflection attacks if a malicious user can use the target machine to impersonate a trusted user.,A mutual authentication protocol requires each party to respond to a random challenge by the other party by encrypting it with a pre-shared key. Often, however, such protocols employ the same pre-shared key for communication with a number of different entities. A malicious user or an attacker can easily compromise this protocol without possessing the correct key by employing a reflection attack on the protocol. Reflection attacks capitalize on mutual authentication schemes in order to trick the target into revealing the secret shared between it and another valid user. In a basic mutual-authentication scheme, a secret is known to both the valid user and the server; this allows them to authenticate. In order that they may verify this shared secret without sending it plainly over the wire, they utilize a Diffie-Hellman-style scheme in which they each pick a value, then request the hash of that value as keyed by the shared secret. In a reflection attack, the attacker claims to be a valid user and requests the hash of a random value from the server. When the server returns this value and requests its own value to be hashed, the attacker opens another connection to the server. This time, the hash requested by the attacker is the value which the server requested in the first connection. When the server returns this hashed value, it is used in the first connection, authenticating the attacker successfully as the impersonated valid user.
302,Authentication Bypass by Assumed-Immutable Data,Base,Incomplete,The authentication scheme or implementation uses key data elements that are assumed to be immutable, but can be controlled or modified by the attacker.,
303,Incorrect Implementation of Authentication Algorithm,Base,Draft,The requirements for the product dictate the use of an established authentication algorithm, but the implementation of the algorithm is incorrect.,This incorrect implementation may allow authentication to be bypassed.
304,Missing Critical Step in Authentication,Base,Draft,The product implements an authentication technique, but it skips a step that weakens the technique.,Authentication techniques should follow the algorithms that define them exactly, otherwise authentication can be bypassed or more easily subjected to brute force attacks.
305,Authentication Bypass by Primary Weakness,Base,Draft,The authentication algorithm is sound, but the implemented mechanism can be bypassed as the result of a separate weakness that is primary to the authentication error.,
306,Missing Authentication for Critical Function,Base,Draft,The product does not perform any authentication for functionality that requires a provable user identity or consumes a significant amount of resources.,As data is migrated to the cloud, if access does not require authentication, it can be easier for attackers to access the data from anywhere on the Internet.
307,Improper Restriction of Excessive Authentication Attempts,Base,Draft,The product does not implement sufficient measures to prevent multiple failed authentication attempts within a short time frame, making it more susceptible to brute force attacks.,
308,Use of Single-factor Authentication,Base,Draft,The use of single-factor authentication can lead to unnecessary risk of compromise when compared with the benefits of a dual-factor authentication scheme.,While the use of multiple authentication schemes is simply piling on more complexity on top of authentication, it is inestimably valuable to have such measures of redundancy. The use of weak, reused, and common passwords is rampant on the internet. Without the added protection of multiple authentication schemes, a single mistake can result in the compromise of an account. For this reason, if multiple schemes are possible and also easy to use, they should be implemented and required.
309,Use of Password System for Primary Authentication,Base,Draft,The use of password systems as the primary means of authentication may be subject to several flaws or shortcomings, each reducing the effectiveness of the mechanism.,
311,Missing Encryption of Sensitive Data,Class,Draft,The product does not encrypt sensitive or critical information before storage or transmission.,The lack of proper data encryption passes up the guarantees of confidentiality, integrity, and accountability that properly implemented encryption conveys.
312,Cleartext Storage of Sensitive Information,Base,Draft,The product stores sensitive information in cleartext within a resource that might be accessible to another control sphere.,Because the information is stored in cleartext (i.e., unencrypted), attackers could potentially read it. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information. When organizations adopt cloud services, it can be easier for attackers to access the data from anywhere on the Internet. In some systems/environments such as cloud, the use of double encryption (at both the software and hardware layer) might be required, and the developer might be solely responsible for both layers, instead of shared responsibility with the administrator of the broader system/environment.
313,Cleartext Storage in a File or on Disk,Variant,Draft,The product stores sensitive information in cleartext in a file, or on disk.,The sensitive information could be read by attackers with access to the file, or with physical or administrator access to the raw disk. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.
314,Cleartext Storage in the Registry,Variant,Draft,The product stores sensitive information in cleartext in the registry.,Attackers can read the information by accessing the registry key. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.
315,Cleartext Storage of Sensitive Information in a Cookie,Variant,Draft,The product stores sensitive information in cleartext in a cookie.,Attackers can use widely-available tools to view the cookie and read the sensitive information. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.
316,Cleartext Storage of Sensitive Information in Memory,Variant,Draft,The product stores sensitive information in cleartext in memory.,The sensitive memory might be saved to disk, stored in a core dump, or remain uncleared if the product crashes, or if the programmer does not properly clear the memory before freeing it. It could be argued that such problems are usually only exploitable by those with administrator privileges. However, swapping could cause the memory to be written to disk and leave it accessible to physical attack afterwards. Core dump files might have insecure permissions or be stored in archive files that are accessible to untrusted people. Or, uncleared sensitive memory might be inadvertently exposed to attackers due to another weakness.
317,Cleartext Storage of Sensitive Information in GUI,Variant,Draft,The product stores sensitive information in cleartext within the GUI.,An attacker can often obtain data from a GUI, even if hidden, by using an API to directly access GUI objects such as windows and menus. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.
318,Cleartext Storage of Sensitive Information in Executable,Variant,Draft,The product stores sensitive information in cleartext in an executable.,Attackers can reverse engineer binary code to obtain secret data. This is especially easy when the cleartext is plain ASCII. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.
319,Cleartext Transmission of Sensitive Information,Base,Draft,The product transmits sensitive or security-critical data in cleartext in a communication channel that can be sniffed by unauthorized actors.,Many communication channels can be sniffed (monitored) by adversaries during data transmission. For example, in networking, packets can traverse many intermediary nodes from the source to the destination, whether across the internet, an internal network, the cloud, etc. Some actors might have privileged access to a network interface or any link along the channel, such as a router, but they might not be authorized to collect the underlying data. As a result, network traffic could be sniffed by adversaries, spilling security-critical data. Applicable communication channels are not limited to software products. Applicable channels include hardware-specific technologies such as internal hardware networks and external debug channels, supporting remote JTAG debugging. When mitigations are not applied to combat adversaries within the product's threat model, this weakness significantly lowers the difficulty of exploitation by such adversaries. When full communications are recorded or logged, such as with a packet dump, an adversary could attempt to obtain the dump long after the transmission has occurred and try to sniff the cleartext from the recorded communications in the dump itself.
321,Use of Hard-coded Cryptographic Key,Variant,Draft,The use of a hard-coded cryptographic key significantly increases the possibility that encrypted data may be recovered.,
322,Key Exchange without Entity Authentication,Base,Draft,The product performs a key exchange with an actor without verifying the identity of that actor.,Performing a key exchange will preserve the integrity of the information sent between two entities, but this will not guarantee that the entities are who they claim they are. This may enable an attacker to impersonate an actor by modifying traffic between the two entities. Typically, this involves a victim client that contacts a malicious server that is impersonating a trusted server. If the client skips authentication or ignores an authentication failure, the malicious server may request authentication information from the user. The malicious server can then use this authentication information to log in to the trusted server using the victim's credentials, sniff traffic between the victim and trusted server, etc.
323,Reusing a Nonce, Key Pair in Encryption,Variant,Incomplete,Nonces should be used for the present occasion and only once.,
324,Use of a Key Past its Expiration Date,Base,Draft,The product uses a cryptographic key or password past its expiration date, which diminishes its safety significantly by increasing the timing window for cracking attacks against that key.,While the expiration of keys does not necessarily ensure that they are compromised, it is a significant concern that keys which remain in use for prolonged periods of time have a decreasing probability of integrity. For this reason, it is important to replace keys within a period of time proportional to their strength.
325,Missing Cryptographic Step,Base,Draft,The product does not implement a required step in a cryptographic algorithm, resulting in weaker encryption than advertised by the algorithm.,
326,Inadequate Encryption Strength,Class,Draft,The product stores or transmits sensitive data using an encryption scheme that is theoretically sound, but is not strong enough for the level of protection required.,A weak encryption scheme can be subjected to brute force attacks that have a reasonable chance of succeeding using current attack methods and resources.
327,Use of a Broken or Risky Cryptographic Algorithm,Class,Draft,The product uses a broken or risky cryptographic algorithm or protocol.,Cryptographic algorithms are the methods by which data is scrambled to prevent observation or influence by unauthorized actors. Insecure cryptography can be exploited to expose sensitive information, modify data in unexpected ways, spoof identities of other users or devices, or other impacts. It is very difficult to produce a secure algorithm, and even high-profile algorithms by accomplished cryptographic experts have been broken. Well-known techniques exist to break or weaken various kinds of cryptography. Accordingly, there are a small number of well-understood and heavily studied algorithms that should be used by most products. Using a non-standard or known-insecure algorithm is dangerous because a determined adversary may be able to break the algorithm and compromise whatever data has been protected. Since the state of cryptography advances so rapidly, it is common for an algorithm to be considered unsafe even if it was once thought to be strong. This can happen when new attacks are discovered, or if computing power increases so much that the cryptographic algorithm no longer provides the amount of protection that was originally thought. For a number of reasons, this weakness is even more challenging to manage with hardware deployment of cryptographic algorithms as opposed to software implementation. First, if a flaw is discovered with hardware-implemented cryptography, the flaw cannot be fixed in most cases without a recall of the product, because hardware is not easily replaceable like software. Second, because the hardware product is expected to work for years, the adversary's computing power will only increase over time.
328,Use of Weak Hash,Base,Draft,The product uses an algorithm that produces a digest (output value) that does not meet security expectations for a hash function that allows an adversary to reasonably determine the original input (preimage attack), find another input that can produce the same hash (2nd preimage attack), or find multiple inputs that evaluate to the same hash (birthday attack).,A hash function is defined as an algorithm that maps arbitrarily sized data into a fixed-sized digest (output) such that the following properties hold: 1. The algorithm is not invertible (also called one-way or not reversible) 2. The algorithm is deterministic; the same input produces the same digest every time Building on this definition, a cryptographic hash function must also ensure that a malicious actor cannot leverage the hash function to have a reasonable chance of success at determining any of the following: 1. the original input (preimage attack), given only the digest 2. another input that can produce the same digest (2nd preimage attack), given the original input 3. a set of two or more inputs that evaluate to the same digest (birthday attack), given the actor can arbitrarily choose the inputs to be hashed and can do so a reasonable amount of times What is regarded as reasonable varies by context and threat model, but in general, reasonable could cover any attack that is more efficient than brute force (i.e., on average, attempting half of all possible combinations). Note that some attacks might be more efficient than brute force but are still not regarded as achievable in the real world. Any algorithm does not meet the above conditions will generally be considered weak for general use in hashing. In addition to algorithmic weaknesses, a hash function can be made weak by using the hash in a security context that breaks its security guarantees. For example, using a hash function without a salt for storing passwords (that are sufficiently short) could enable an adversary to create a rainbow table [REF-637] to recover the password under certain conditions; this attack works against such hash functions as MD5, SHA-1, and SHA-2.
329,Generation of Predictable IV with CBC Mode,Variant,Draft,The product generates and uses a predictable initialization Vector (IV) with Cipher Block Chaining (CBC) Mode, which causes algorithms to be susceptible to dictionary attacks when they are encrypted under the same key.,CBC mode eliminates a weakness of Electronic Code Book (ECB) mode by allowing identical plaintext blocks to be encrypted to different ciphertext blocks. This is possible by the XOR-ing of an IV with the initial plaintext block so that every plaintext block in the chain is XOR'd with a different value before encryption. If IVs are reused, then identical plaintexts would be encrypted to identical ciphertexts. However, even if IVs are not identical but are predictable, then they still break the security of CBC mode against Chosen Plaintext Attacks (CPA).
330,Use of Insufficiently Random Values,Class,Stable,The product uses insufficiently random numbers or values in a security context that depends on unpredictable numbers.,When product generates predictable values in a context requiring unpredictability, it may be possible for an attacker to guess the next value that will be generated, and use this guess to impersonate another user or access sensitive information.
331,Insufficient Entropy,Base,Draft,The product uses an algorithm or scheme that produces insufficient entropy, leaving patterns or clusters of values that are more likely to occur than others.,
332,Insufficient Entropy in PRNG,Variant,Draft,The lack of entropy available for, or used by, a Pseudo-Random Number Generator (PRNG) can be a stability and security threat.,
333,Improper Handling of Insufficient Entropy in TRNG,Variant,Draft,True random number generators (TRNG) generally have a limited source of entropy and therefore can fail or block.,The rate at which true random numbers can be generated is limited. It is important that one uses them only when they are needed for security.
334,Small Space of Random Values,Base,Draft,The number of possible random values is smaller than needed by the product, making it more susceptible to brute force attacks.,
335,Incorrect Usage of Seeds in Pseudo-Random Number Generator (PRNG),Base,Draft,The product uses a Pseudo-Random Number Generator (PRNG) but does not correctly manage seeds.,PRNGs are deterministic and, while their output appears random, they cannot actually create entropy. They rely on cryptographically secure and unique seeds for entropy so proper seeding is critical to the secure operation of the PRNG. Management of seeds could be broken down into two main areas: (1) protecting seeds as cryptographic material (such as a cryptographic key); (2) whenever possible, using a uniquely generated seed from a cryptographically secure source PRNGs require a seed as input to generate a stream of numbers that are functionally indistinguishable from random numbers. While the output is, in many cases, sufficient for cryptographic uses, the output of any PRNG is directly determined by the seed provided as input. If the seed can be ascertained by a third party, the entire output of the PRNG can be made known to them. As such, the seed should be kept secret and should ideally not be able to be guessed. For example, the current time may be a poor seed. Knowing the approximate time the PRNG was seeded greatly reduces the possible key space. Seeds do not necessarily need to be unique, but reusing seeds may open up attacks if the seed is discovered.
336,Same Seed in Pseudo-Random Number Generator (PRNG),Variant,Draft,A Pseudo-Random Number Generator (PRNG) uses the same seed each time the product is initialized.,Given the deterministic nature of PRNGs, using the same seed for each initialization will lead to the same output in the same order. If an attacker can guess (or knows) the seed, then the attacker may be able to determine the random numbers that will be produced from the PRNG.
337,Predictable Seed in Pseudo-Random Number Generator (PRNG),Variant,Draft,A Pseudo-Random Number Generator (PRNG) is initialized from a predictable seed, such as the process ID or system time.,The use of predictable seeds significantly reduces the number of possible seeds that an attacker would need to test in order to predict which random numbers will be generated by the PRNG.
338,Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG),Base,Draft,The product uses a Pseudo-Random Number Generator (PRNG) in a security context, but the PRNG's algorithm is not cryptographically strong.,When a non-cryptographic PRNG is used in a cryptographic context, it can expose the cryptography to certain types of attacks. Often a pseudo-random number generator (PRNG) is not designed for cryptography. Sometimes a mediocre source of randomness is sufficient or preferable for algorithms that use random numbers. Weak generators generally take less processing power and/or do not use the precious, finite, entropy sources on a system. While such PRNGs might have very useful features, these same features could be used to break the cryptography.
339,Small Seed Space in PRNG,Variant,Draft,A Pseudo-Random Number Generator (PRNG) uses a relatively small seed space, which makes it more susceptible to brute force attacks.,PRNGs are entirely deterministic once seeded, so it should be extremely difficult to guess the seed. If an attacker can collect the outputs of a PRNG and then brute force the seed by trying every possibility to see which seed matches the observed output, then the attacker will know the output of any subsequent calls to the PRNG. A small seed space implies that the attacker will have far fewer possible values to try to exhaust all possibilities.
340,Generation of Predictable Numbers or Identifiers,Class,Incomplete,The product uses a scheme that generates numbers or identifiers that are more predictable than required.,
341,Predictable from Observable State,Base,Draft,A number or object is predictable based on observations that the attacker can make about the state of the system or network, such as time, process ID, etc.,
342,Predictable Exact Value from Previous Values,Base,Draft,An exact value or random number can be precisely predicted by observing previous values.,
343,Predictable Value Range from Previous Values,Base,Draft,The product's random number generator produces a series of values which, when observed, can be used to infer a relatively small range of possibilities for the next value that could be generated.,The output of a random number generator should not be predictable based on observations of previous values. In some cases, an attacker cannot predict the exact value that will be produced next, but can narrow down the possibilities significantly. This reduces the amount of effort to perform a brute force attack. For example, suppose the product generates random numbers between 1 and 100, but it always produces a larger value until it reaches 100. If the generator produces an 80, then the attacker knows that the next value will be somewhere between 81 and 100. Instead of 100 possibilities, the attacker only needs to consider 20.
344,Use of Invariant Value in Dynamically Changing Context,Base,Draft,The product uses a constant value, name, or reference, but this value can (or should) vary across different environments.,
345,Insufficient Verification of Data Authenticity,Class,Draft,The product does not sufficiently verify the origin or authenticity of data, in a way that causes it to accept invalid data.,
346,Origin Validation Error,Class,Draft,The product does not properly verify that the source of data or communication is valid.,
347,Improper Verification of Cryptographic Signature,Base,Draft,The product does not verify, or incorrectly verifies, the cryptographic signature for data.,
348,Use of Less Trusted Source,Base,Draft,The product has two different sources of the same data or information, but it uses the source that has less support for verification, is less trusted, or is less resistant to attack.,
349,Acceptance of Extraneous Untrusted Data With Trusted Data,Base,Draft,The product, when processing trusted data, accepts any untrusted data that is also included with the trusted data, treating the untrusted data as if it were trusted.,
350,Reliance on Reverse DNS Resolution for a Security-Critical Action,Variant,Draft,The product performs reverse DNS resolution on an IP address to obtain the hostname and make a security decision, but it does not properly ensure that the IP address is truly associated with the hostname.,Since DNS names can be easily spoofed or misreported, and it may be difficult for the product to detect if a trusted DNS server has been compromised, DNS names do not constitute a valid authentication mechanism. When the product performs a reverse DNS resolution for an IP address, if an attacker controls the DNS server for that IP address, then the attacker can cause the server to return an arbitrary hostname. As a result, the attacker may be able to bypass authentication, cause the wrong hostname to be recorded in log files to hide activities, or perform other attacks. Attackers can spoof DNS names by either (1) compromising a DNS server and modifying its records (sometimes called DNS cache poisoning), or (2) having legitimate control over a DNS server associated with their IP address.
351,Insufficient Type Distinction,Base,Draft,The product does not properly distinguish between different types of elements in a way that leads to insecure behavior.,
353,Missing Support for Integrity Check,Base,Draft,The product uses a transmission protocol that does not include a mechanism for verifying the integrity of the data during transmission, such as a checksum.,If integrity check values or checksums are omitted from a protocol, there is no way of determining if data has been corrupted in transmission. The lack of checksum functionality in a protocol removes the first application-level check of data that can be used. The end-to-end philosophy of checks states that integrity checks should be performed at the lowest level that they can be completely implemented. Excluding further sanity checks and input validation performed by applications, the protocol's checksum is the most important level of checksum, since it can be performed more completely than at any previous level and takes into account entire messages, as opposed to single packets.
354,Improper Validation of Integrity Check Value,Base,Draft,The product does not validate or incorrectly validates the integrity check values or checksums of a message. This may prevent it from detecting if the data has been modified or corrupted in transmission.,Improper validation of checksums before use results in an unnecessary risk that can easily be mitigated. The protocol specification describes the algorithm used for calculating the checksum. It is then a simple matter of implementing the calculation and verifying that the calculated checksum and the received checksum match. Improper verification of the calculated checksum and the received checksum can lead to far greater consequences.
356,Product UI does not Warn User of Unsafe Actions,Base,Incomplete,The product's user interface does not warn the user before undertaking an unsafe action on behalf of that user. This makes it easier for attackers to trick users into inflicting damage to their system.,Product systems should warn users that a potentially dangerous action may occur if the user proceeds. For example, if the user downloads a file from an unknown source and attempts to execute the file on their machine, then the application's GUI can indicate that the file is unsafe.
357,Insufficient UI Warning of Dangerous Operations,Base,Draft,The user interface provides a warning to a user regarding dangerous or sensitive operations, but the warning is not noticeable enough to warrant attention.,
358,Improperly Implemented Security Check for Standard,Base,Draft,The product does not implement or incorrectly implements one or more security-relevant checks as specified by the design of a standardized algorithm, protocol, or technique.,
359,Exposure of Private Personal Information to an Unauthorized Actor,Base,Incomplete,The product does not properly prevent a person's private, personal information from being accessed by actors who either (1) are not explicitly authorized to access the information or (2) do not have the implicit consent of the person about whom the information is collected.,There are many types of sensitive information that products must protect from attackers, including system data, communications, configuration, business secrets, intellectual property, and an individual's personal (private) information. Private personal information may include a password, phone number, geographic location, personal messages, credit card number, etc. Private information is important to consider whether the person is a user of the product, or part of a data set that is processed by the product. An exposure of private information does not necessarily prevent the product from working properly, and in fact the exposure might be intended by the developer, e.g. as part of data sharing with other organizations. However, the exposure of personal private information can still be undesirable or explicitly prohibited by law or regulation. Some types of private information include: Government identifiers, such as Social Security Numbers Contact information, such as home addresses and telephone numbers Geographic location - where the user is (or was) Employment history Financial data - such as credit card numbers, salary, bank accounts, and debts Pictures, video, or audio Behavioral patterns - such as web surfing history, when certain activities are performed, etc. Relationships (and types of relationships) with others - family, friends, contacts, etc. Communications - e-mail addresses, private messages, text messages, chat logs, etc. Health - medical conditions, insurance status, prescription records Account passwords and other credentials Some of this information may be characterized as PII (Personally Identifiable Information), Protected Health Information (PHI), etc. Categories of private information may overlap or vary based on the intended usage or the policies and practices of a particular industry. Sometimes data that is not labeled as private can have a privacy implication in a different context. For example, student identification numbers are usually not considered private because there is no explicit and publicly-available mapping to an individual student's personal information. However, if a school generates identification numbers based on student social security numbers, then the identification numbers should be considered private.
360,Trust of System Event Data,Base,Incomplete,Security based on event locations are insecure and can be spoofed.,Events are a messaging system which may provide control data to programs listening for events. Events often do not have any type of authentication framework to allow them to be verified from a trusted source. Any application, in Windows, on a given desktop can send a message to any window on the same desktop. There is no authentication framework for these messages. Therefore, any message can be used to manipulate any process on the desktop if the process does not check the validity and safeness of those messages.
362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),Class,Draft,The product contains a code sequence that can run concurrently with other code, and the code sequence requires temporary, exclusive access to a shared resource, but a timing window exists in which the shared resource can be modified by another code sequence that is operating concurrently.,This can have security implications when the expected synchronization is in security-critical code, such as recording whether a user is authenticated or modifying important state information that should not be influenced by an outsider. A race condition occurs within concurrent environments, and is effectively a property of a code sequence. Depending on the context, a code sequence may be in the form of a function call, a small number of instructions, a series of program invocations, etc. A race condition violates these properties, which are closely related: Exclusivity - the code sequence is given exclusive access to the shared resource, i.e., no other code sequence can modify properties of the shared resource before the original sequence has completed execution. Atomicity - the code sequence is behaviorally atomic, i.e., no other thread or process can concurrently execute the same sequence of instructions (or a subset) against the same resource. A race condition exists when an interfering code sequence can still access the shared resource, violating exclusivity. Programmers may assume that certain code sequences execute too quickly to be affected by an interfering code sequence; when they are not, this violates atomicity. For example, the single x++ statement may appear atomic at the code layer, but it is actually non-atomic at the instruction layer, since it involves a read (the original value of x), followed by a computation (x+1), followed by a write (save the result to x). The interfering code sequence could be trusted or untrusted. A trusted interfering code sequence occurs within the product; it cannot be modified by the attacker, and it can only be invoked indirectly. An untrusted interfering code sequence can be authored directly by the attacker, and typically it is external to the vulnerable product.
363,Race Condition Enabling Link Following,Base,Draft,The product checks the status of a file or directory before accessing it, which produces a race condition in which the file can be replaced with a link before the access is performed, causing the product to access the wrong file.,While developers might expect that there is a very narrow time window between the time of check and time of use, there is still a race condition. An attacker could cause the product to slow down (e.g. with memory consumption), causing the time window to become larger. Alternately, in some situations, the attacker could win the race by performing a large number of attacks.
364,Signal Handler Race Condition,Base,Incomplete,The product uses a signal handler that introduces a race condition.,Race conditions frequently occur in signal handlers, since signal handlers support asynchronous actions. These race conditions have a variety of root causes and symptoms. Attackers may be able to exploit a signal handler race condition to cause the product state to be corrupted, possibly leading to a denial of service or even code execution. These issues occur when non-reentrant functions, or state-sensitive actions occur in the signal handler, where they may be called at any time. These behaviors can violate assumptions being made by the regular code that is interrupted, or by other signal handlers that may also be invoked. If these functions are called at an inopportune moment - such as while a non-reentrant function is already running - memory corruption could occur that may be exploitable for code execution. Another signal race condition commonly found occurs when free is called within a signal handler, resulting in a double free and therefore a write-what-where condition. Even if a given pointer is set to NULL after it has been freed, a race condition still exists between the time the memory was freed and the pointer was set to NULL. This is especially problematic if the same signal handler has been set for more than one signal -- since it means that the signal handler itself may be reentered. There are several known behaviors related to signal handlers that have received the label of signal handler race condition: Shared state (e.g. global data or static variables) that are accessible to both a signal handler and regular code Shared state between a signal handler and other signal handlers Use of non-reentrant functionality within a signal handler - which generally implies that shared state is being used. For example, malloc() and free() are non-reentrant because they may use global or static data structures for managing memory, and they are indirectly used by innocent-seeming functions such as syslog(); these functions could be exploited for memory corruption and, possibly, code execution. Association of the same signal handler function with multiple signals - which might imply shared state, since the same code and resources are accessed. For example, this can be a source of double-free and use-after-free weaknesses. Use of setjmp and longjmp, or other mechanisms that prevent a signal handler from returning control back to the original functionality While not technically a race condition, some signal handlers are designed to be called at most once, and being called more than once can introduce security problems, even when there are not any concurrent calls to the signal handler. This can be a source of double-free and use-after-free weaknesses. Signal handler vulnerabilities are often classified based on the absence of a specific protection mechanism, although this style of classification is discouraged in CWE because programmers often have a choice of several different mechanisms for addressing the weakness. Such protection mechanisms may preserve exclusivity of access to the shared resource, and behavioral atomicity for the relevant code: Avoiding shared state Using synchronization in the signal handler Using synchronization in the regular code Disabling or masking other signals, which provides atomicity (which effectively ensures exclusivity)
366,Race Condition within a Thread,Base,Draft,If two threads of execution use a resource simultaneously, there exists the possibility that resources may be used while invalid, in turn making the state of execution undefined.,
367,Time-of-check Time-of-use (TOCTOU) Race Condition,Base,Incomplete,The product checks the state of a resource before using that resource, but the resource's state can change between the check and the use in a way that invalidates the results of the check. This can cause the product to perform invalid actions when the resource is in an unexpected state.,This weakness can be security-relevant when an attacker can influence the state of the resource between check and use. This can happen with shared resources such as files, memory, or even variables in multithreaded programs.
368,Context Switching Race Condition,Base,Draft,A product performs a series of non-atomic actions to switch between contexts that cross privilege or other security boundaries, but a race condition allows an attacker to modify or misrepresent the product's behavior during the switch.,This is commonly seen in web browser vulnerabilities in which the attacker can perform certain actions while the browser is transitioning from a trusted to an untrusted domain, or vice versa, and the browser performs the actions on one domain using the trust level and resources of the other domain.
369,Divide By Zero,Base,Draft,The product divides a value by zero.,This weakness typically occurs when an unexpected value is provided to the product, or if an error occurs that is not properly detected. It frequently occurs in calculations involving physical dimensions such as size, length, width, and height.
370,Missing Check for Certificate Revocation after Initial Check,Variant,Draft,The product does not check the revocation status of a certificate after its initial revocation check, which can cause the product to perform privileged actions even after the certificate is revoked at a later time.,If the revocation status of a certificate is not checked before each action that requires privileges, the system may be subject to a race condition. If a certificate is revoked after the initial check, all subsequent actions taken with the owner of the revoked certificate will lose all benefits guaranteed by the certificate. In fact, it is almost certain that the use of a revoked certificate indicates malicious activity.
372,Incomplete Internal State Distinction,Base,Draft,The product does not properly determine which state it is in, causing it to assume it is in state X when in fact it is in state Y, causing it to perform incorrect operations in a security-relevant manner.,
374,Passing Mutable Objects to an Untrusted Method,Base,Draft,The product sends non-cloned mutable data as an argument to a method or function.,The function or method that has been called can alter or delete the mutable data. This could violate assumptions that the calling function has made about its state. In situations where unknown code is called with references to mutable data, this external code could make changes to the data sent. If this data was not previously cloned, the modified data might not be valid in the context of execution.
375,Returning a Mutable Object to an Untrusted Caller,Base,Draft,Sending non-cloned mutable data as a return value may result in that data being altered or deleted by the calling function.,In situations where functions return references to mutable data, it is possible that the external code which called the function may make changes to the data sent. If this data was not previously cloned, the class will then be using modified data which may violate assumptions about its internal state.
377,Insecure Temporary File,Class,Incomplete,Creating and using insecure temporary files can leave application and system data vulnerable to attack.,
378,Creation of Temporary File With Insecure Permissions,Base,Draft,Opening temporary files without appropriate measures or controls can leave the file, its contents and any function that it impacts vulnerable to attack.,
379,Creation of Temporary File in Directory with Insecure Permissions,Base,Incomplete,The product creates a temporary file in a directory whose permissions allow unintended actors to determine the file's existence or otherwise access that file.,On some operating systems, the fact that the temporary file exists may be apparent to any user with sufficient privileges to access that directory. Since the file is visible, the application that is using the temporary file could be known. If one has access to list the processes on the system, the attacker has gained information about what the user is doing at that time. By correlating this with the applications the user is running, an attacker could potentially discover what a user's actions are. From this, higher levels of security could be breached.
382,J2EE Bad Practices: Use of System.exit(),Variant,Draft,A J2EE application uses System.exit(), which also shuts down its container.,It is never a good idea for a web application to attempt to shut down the application container. Access to a function that can shut down the application is an avenue for Denial of Service (DoS) attacks.
383,J2EE Bad Practices: Direct Use of Threads,Variant,Draft,Thread management in a Web application is forbidden in some circumstances and is always highly error prone.,Thread management in a web application is forbidden by the J2EE standard in some circumstances and is always highly error prone. Managing threads is difficult and is likely to interfere in unpredictable ways with the behavior of the application container. Even without interfering with the container, thread management usually leads to bugs that are hard to detect and diagnose like deadlock, race conditions, and other synchronization errors.
385,Covert Timing Channel,Base,Incomplete,Covert timing channels convey information by modulating some aspect of system behavior over time, so that the program receiving the information can observe system behavior and infer protected information.,In some instances, knowing when data is transmitted between parties can provide a malicious user with privileged information. Also, externally monitoring the timing of operations can potentially reveal sensitive data. For example, a cryptographic operation can expose its internal state if the time it takes to perform the operation varies, based on the state. Covert channels are frequently classified as either storage or timing channels. Some examples of covert timing channels are the system's paging rate, the time a certain transaction requires to execute, and the time it takes to gain access to a shared bus.
386,Symbolic Name not Mapping to Correct Object,Base,Draft,A constant symbolic reference to an object is used, even though the reference can resolve to a different object over time.,
390,Detection of Error Condition Without Action,Base,Draft,The product detects a specific error, but takes no actions to handle the error.,
391,Unchecked Error Condition,Base,Incomplete,[PLANNED FOR DEPRECATION. SEE MAINTENANCE NOTES AND CONSIDER CWE-252, CWE-248, OR CWE-1069.] Ignoring exceptions and other error conditions may allow an attacker to induce unexpected behavior unnoticed.,
392,Missing Report of Error Condition,Base,Draft,The product encounters an error but does not provide a status code or return value to indicate that an error has occurred.,
393,Return of Wrong Status Code,Base,Draft,A function or operation returns an incorrect return value or status code that does not indicate an error, but causes the product to modify its behavior based on the incorrect result.,This can lead to unpredictable behavior. If the function is used to make security-critical decisions or provide security-critical information, then the wrong status code can cause the product to assume that an action is safe, even when it is not.
394,Unexpected Status Code or Return Value,Base,Draft,The product does not properly check when a function or operation returns a value that is legitimate for the function, but is not expected by the product.,
395,Use of NullPointerException Catch to Detect NULL Pointer Dereference,Base,Draft,Catching NullPointerException should not be used as an alternative to programmatic checks to prevent dereferencing a null pointer.,Programmers typically catch NullPointerException under three circumstances: The program contains a null pointer dereference. Catching the resulting exception was easier than fixing the underlying problem. The program explicitly throws a NullPointerException to signal an error condition. The code is part of a test harness that supplies unexpected input to the classes under test. Of these three circumstances, only the last is acceptable.
396,Declaration of Catch for Generic Exception,Base,Draft,Catching overly broad exceptions promotes complex error handling code that is more likely to contain security vulnerabilities.,Multiple catch blocks can get ugly and repetitive, but condensing catch blocks by catching a high-level class like Exception can obscure exceptions that deserve special treatment or that should not be caught at this point in the program. Catching an overly broad exception essentially defeats the purpose of Java's typed exceptions, and can become particularly dangerous if the program grows and begins to throw new types of exceptions. The new exception types will not receive any attention.
397,Declaration of Throws for Generic Exception,Base,Draft,Throwing overly broad exceptions promotes complex error handling code that is more likely to contain security vulnerabilities.,Declaring a method to throw Exception or Throwable makes it difficult for callers to perform proper error handling and error recovery. Java's exception mechanism, for example, is set up to make it easy for callers to anticipate what can go wrong and write code to handle each specific exceptional circumstance. Declaring that a method throws a generic form of exception defeats this system.
